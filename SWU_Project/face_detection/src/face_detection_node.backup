#!/usr/bin/env python3
import rclpy
from rclpy.node import Node
import cv2
import yaml
from pycoral.utils.edgetpu import make_interpreter
from pycoral.adapters import common, detect

class FaceDetectionNode(Node):
    def __init__(self):
        super().__init__('face_detection_node')

        # Configuration file path
        config_path = self.declare_parameter('config_path', '/home/ubuntu/ros2_ws/install/face_detection/share/face_detection/config/face_tracker.yaml').value
        with open(config_path, 'r') as file:
            config = yaml.safe_load(file)

        # Model path configuration
        self.model_path = '/home/ubuntu/ros2_ws/install/face_detection/share/face_detection/models/ssd_mobilenet_v2_face_quant_postprocess_edgetpu.tflite'
        self.detection_threshold = config['detection_threshold']

        try:
            self.interpreter = make_interpreter(self.model_path)
            self.interpreter.allocate_tensors()
            self.get_logger().info("Model successfully loaded.")
        except Exception as e:
            self.get_logger().error(f"Failed to load model: {e}")
            rclpy.shutdown()
            return

        self.cap = cv2.VideoCapture(0)
        if not self.cap.isOpened():
            self.get_logger().error("Failed to open camera.")
            rclpy.shutdown()
            return

        self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
        self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
        self.timer = self.create_timer(0.1, self.detect_faces)

    def preprocess_and_infer(self, frame):
        _, scale = common.set_resized_input(self.interpreter, (320, 320), lambda size: cv2.resize(frame, size))
        self.interpreter.invoke()
        return detect.get_objects(self.interpreter, score_threshold=self.detection_threshold, image_scale=scale)

    def draw_bounding_boxes(self, frame, faces):
        for face in faces:
            bbox = face.bbox
            xmin = max(0, bbox.xmin)
            ymin = max(0, bbox.ymin)
            xmax = min(frame.shape[1], bbox.xmax)
            ymax = min(frame.shape[0], bbox.ymax)
            cv2.rectangle(frame, (xmin, ymin), (xmax, ymax), (0, 255, 0), 2)
            cv2.putText(frame, f'Score: {face.score:.2f}', (xmin, ymin - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)
            self.get_logger().info(f"Face detected - Score: {face.score:.2f}, Bbox: {xmin}, {ymin}, {xmax}, {ymax}")

    def detect_faces(self):
        ret, frame = self.cap.read()
        if not ret:
            self.get_logger().error("Failed to capture frame from camera.")
            return

        try:
            faces = self.preprocess_and_infer(frame)
            if not faces:
                self.get_logger().info("No faces detected.")
            else:
                self.get_logger().info(f"Detected {len(faces)} faces.")
                self.draw_bounding_boxes(frame, faces)
        except Exception as e:
            self.get_logger().error(f"Error during model inference: {e}")

        cv2.imshow('Face Detection', frame)
        if cv2.waitKey(1) & 0xFF == ord('q'):
            self.cap.release()
            cv2.destroyAllWindows()
            rclpy.shutdown()

def main(args=None):
    rclpy.init(args=args)
    node = FaceDetectionNode()
    rclpy.spin(node)
    node.destroy_node()
    rclpy.shutdown()

if __name__ == '__main__':
    main()
